{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example probe training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for generating dataset of activations from OthelloGPT project\n",
    "\n",
    "Probe is just linear layer defined in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from data.othello import Othello, OthelloBoardState\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.model import GPT, GPTConfig, GPTforProbing\n",
    "from mingpt.probe_trainer import Trainer, TrainerConfig\n",
    "from mingpt.probe_model import BatteryProbeClassification, BatteryProbeClassificationTwoLayer\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train classification network')\n",
    "parser.add_argument('--layer',\n",
    "                    required=True,\n",
    "                    default=-1,\n",
    "                    type=int)\n",
    "\n",
    "parser.add_argument('--epo',\n",
    "                    default=16,\n",
    "                    type=int)\n",
    "\n",
    "parser.add_argument('--twolayer',\n",
    "                    dest='twolayer', \n",
    "                    action='store_true')\n",
    "\n",
    "parser.add_argument('--mid_dim',\n",
    "                    default=128,\n",
    "                    type=int)\n",
    "\n",
    "# means testing against randomly initialized model rather than a ckpt\n",
    "parser.add_argument('--random',\n",
    "                    dest='random', \n",
    "                    action='store_true')\n",
    "\n",
    "parser.add_argument('--ckpt',\n",
    "                    dest='ckpt', \n",
    "                    type=str)\n",
    "\n",
    "# should be \"state\" for board state probe\n",
    "# or \"player\" for player type probe\n",
    "# or \"turn\" for turn probe\n",
    "parser.add_argument('--type',\n",
    "                    default=\"state\", \n",
    "                    type=str)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "folder_name = f\"bias/probes/{args.type}\"\n",
    "\n",
    "if args.twolayer:\n",
    "    folder_name = folder_name + f\"_tl{args.mid_dim}\"  # tl for probes without batchnorm\n",
    "if args.random:\n",
    "    folder_name = folder_name + \"_random\"\n",
    "\n",
    "print(f\"Running experiment for {folder_name}\")\n",
    "othello = Othello(data_root=\"othello_1player\", n_games=10000, deduplicate=False, test_split=0)\n",
    "\n",
    "player_types, games = zip(*othello)\n",
    "train_dataset = CharDataset(games)\n",
    "# train_dataset = CharDataset(othello)\n",
    "\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPTforProbing(mconf, probe_layer=args.layer)\n",
    "if args.random:\n",
    "    model.apply(model._init_weights)\n",
    "if args.ckpt:  \n",
    "    load_res = model.load_state_dict(torch.load(f\"./ckpts/{args.ckpt}.ckpt\"))\n",
    "else:\n",
    "    raise Exception(\"not given ckpt path or random flag\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)\n",
    "\n",
    "# creating dataset of activations and properties\n",
    "loader = DataLoader(train_dataset, shuffle=False, pin_memory=True, batch_size=1, num_workers=1)\n",
    "act_container = []\n",
    "property_container = []\n",
    "\n",
    "for i, (x, y) in tqdm(enumerate(loader), total=len(loader)):\n",
    "    tbf = [train_dataset.itos[_] for _ in x.tolist()[0]]\n",
    "    # truncates game if it is less than 60 moves\n",
    "    valid_until = tbf.index(-100) if -100 in tbf else 999\n",
    "\n",
    "    properties = []\n",
    "    # get properties (board state or player type)\n",
    "    if args.type == \"state\":\n",
    "        ob = OthelloBoardState()\n",
    "        for i, move in enumerate(tbf[:valid_until]):\n",
    "            ob.update([move])\n",
    "\n",
    "            # flipping states so always from moving player's perspective\n",
    "            fixed_state = np.array(ob.get_state())\n",
    "            if ob.get_next_hand_color() == 1:\n",
    "                fixed_state = 2 - fixed_state\n",
    "            properties.append(fixed_state)\n",
    "\n",
    "    elif args.type == \"player\":\n",
    "        properties = [[player_types[i]] for _ in range(len(tbf[:valid_until]))]\n",
    "    \n",
    "    elif args.type == \"turn\":\n",
    "        ob = OthelloBoardState()\n",
    "        for i, move in enumerate(tbf[:valid_until]):\n",
    "            ob.update([move])\n",
    "\n",
    "            properties.append([ob.get_next_hand_color()])\n",
    "\n",
    "    property_container.extend(properties)\n",
    "\n",
    "    # gets activations for each move\n",
    "    act = model(x.to(device))[0, ...].detach().cpu()  # [block_size, f]\n",
    "    act = np.array([_[0] for _ in act.split(1, dim=0)[:valid_until]])\n",
    "    act_container.extend(act)\n",
    "\n",
    "    assert len(act_container) == len(property_container)\n",
    "\n",
    "# creating probe\n",
    "if args.type == \"state\":\n",
    "    probe_class = 3\n",
    "    num_task = 64\n",
    "elif args.type == \"player\":\n",
    "    probe_class = 4\n",
    "    num_task = 1\n",
    "elif args.type == \"turn\":\n",
    "    probe_class = 2\n",
    "    num_task = 1\n",
    "else:\n",
    "    raise Exception(\"invalid probe type given\")\n",
    "\n",
    "if args.twolayer:\n",
    "    probe = BatteryProbeClassificationTwoLayer(device, probe_class=probe_class, num_task=num_task, mid_dim=args.mid_dim)\n",
    "else:\n",
    "    probe = BatteryProbeClassification(device, probe_class=probe_class, num_task=num_task)\n",
    "    \n",
    "\n",
    "class ProbingDataset(Dataset):\n",
    "    def __init__(self, act, y):\n",
    "        assert len(act) == len(y)\n",
    "        print(f\"{len(act)} pairs loaded...\")\n",
    "        self.act = act\n",
    "        self.y = y\n",
    "        # print(np.sum(np.array(y)==0), np.sum(np.array(y)==1), np.sum(np.array(y)==2))\n",
    "        print(\"y:\", np.unique(y, return_counts=True))\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.act[idx], torch.tensor(self.y[idx]).to(torch.long)\n",
    "\n",
    "probing_dataset = ProbingDataset(act_container, property_container)\n",
    "train_size = int(0.8 * len(probing_dataset))\n",
    "test_size = len(probing_dataset) - train_size\n",
    "probe_train_dataset, probe_test_dataset = torch.utils.data.random_split(probing_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "max_epochs = args.epo\n",
    "t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=max_epochs, \n",
    "    batch_size=1024, \n",
    "    learning_rate=1e-3,\n",
    "    betas=(.9, .999), \n",
    "    lr_decay=True, \n",
    "    warmup_tokens=len(train_dataset)*5, \n",
    "    final_tokens=len(train_dataset)*max_epochs,\n",
    "    num_workers=0, \n",
    "    weight_decay=0., \n",
    "    ckpt_path=os.path.join(\"./ckpts/\", folder_name, f\"layer{args.layer}\")\n",
    ")\n",
    "trainer = Trainer(probe, probe_train_dataset, probe_test_dataset, tconf)\n",
    "trainer.train(prt=True)\n",
    "trainer.save_traces()\n",
    "trainer.save_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example of training logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "LAYER = 3\n",
    "y = np.array([j for i in range(len(all_first_token_residuals[0])) for j in range(NUM_WORDS)])\n",
    "X = all_last_token_residuals[LAYER, :].reshape(-1, d_model)\n",
    "\n",
    "# Assuming X is your input data and y are your labels\n",
    "# X = np.random.rand(batch_size, 768)  # replace with your actual data\n",
    "# y = np.random.randint(0, 3, batch_size)  # replace with your actual labels\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "indices = to_numpy(torch.randperm(len(X))[:10000])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[indices], y[indices], test_size=0.1, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "lr_model = LogisticRegression(multi_class='ovr', solver='saga', random_state=42, max_iter=100, C=1.0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "\n",
    "# Print a classification report\n",
    "y_pred = lr_model.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))\n",
    "y_pred = lr_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall process:\n",
    "- generate dataset of embeddings\n",
    "    - pass in many different sentences\n",
    "    - save residual stream after each layer\n",
    "    - label for each token's residual is the true word index in sentence (or paragraph or whatever)\n",
    "- train logistic regression model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
