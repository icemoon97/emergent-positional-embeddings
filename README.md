# Emergent Positional Embeddings

Final project for LING 334, trying to extend results from [Neel Nanda's quick invesitgation](https://www.lesswrong.com/posts/Ln7D2aYgmPgjhpEeA/tiny-mech-interp-projects-emergent-positional-embeddings-of) of whether language models like GPT-2 learn emergent representations of relative position, like "is this token the 2nd word in the sentence?"
