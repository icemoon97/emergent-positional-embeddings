{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import transformer_lens\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "spacy_model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device_name = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device_name = \"cuda\" # CUDA for NVIDIA GPU\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(f\"Device: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2-small\"\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50256,  1212,   318,   257,  1332,   286, 11241, 11341,    11,  2491,\n",
      "        14284,   968,   263,    11, 28796,   430,  2411,   506,  4775,    11,\n",
      "         3169,   417,   399,  5282,    11,   366,   538,   291, 40484],\n",
      "       device='cuda:0')\n",
      "['<|endoftext|>', 'This', ' is', ' a', ' test', ' of', ' token', 'izers', ',', ' running', ' jumping', ' New', 'er', ',', ' wow', 'ra', 'rel', 'ong', 'word', ',', ' Ne', 'el', ' N', 'anda', ',', ' \"', 'ep', 'ic', '\"!']\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a test of tokenizers, running jumping Newer, wowrarelongword, Neel Nanda, \\\"epic\\\"!\"\n",
    "\n",
    "gpt_tokens = model.to_tokens(text).squeeze(0)\n",
    "gpt_tokens_str = [model.to_single_str_token(int(t)) for t in gpt_tokens]\n",
    "\n",
    "print(gpt_tokens)\n",
    "print(gpt_tokens_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'test', 'of', 'tokenizers', 'running', 'jumping', 'Newer', 'wowrarelongword', 'Neel', 'Nanda', 'epic']\n"
     ]
    }
   ],
   "source": [
    "doc = spacy_model(text)\n",
    "word_idxs = [t.text for t in doc if t.is_alpha]\n",
    "print(word_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<|endoftext|>', 'NA'),\n",
       " ('This', 0),\n",
       " ('is', 1),\n",
       " ('a', 2),\n",
       " ('test', 3),\n",
       " ('of', 4),\n",
       " ('token', 5),\n",
       " ('izers', 5),\n",
       " (',', 'NA'),\n",
       " ('running', 6),\n",
       " ('jumping', 7),\n",
       " ('New', 8),\n",
       " ('er', 8),\n",
       " (',', 'NA'),\n",
       " ('wow', 9),\n",
       " ('ra', 9),\n",
       " ('rel', 9),\n",
       " ('ong', 9),\n",
       " ('word', 9),\n",
       " (',', 'NA'),\n",
       " ('Ne', 10),\n",
       " ('el', 10),\n",
       " ('N', 11),\n",
       " ('anda', 11),\n",
       " (',', 'NA'),\n",
       " ('\"', 'NA'),\n",
       " ('ep', 12),\n",
       " ('ic', 12),\n",
       " ('\"!', 'NA')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "cur = 0 # current word index\n",
    "sub_idx = 0 # sub index of current word\n",
    "\n",
    "result = []\n",
    "while i < len(gpt_tokens_str):\n",
    "    t = gpt_tokens_str[i].strip()\n",
    "\n",
    "    cur_word = word_idxs[cur]\n",
    "    # if token is part of current word, update sub_idx, continue to next token\n",
    "    if cur_word.find(t, sub_idx) != -1:\n",
    "        result.append((t, cur))\n",
    "        sub_idx += len(t)\n",
    "        i += 1\n",
    "    else:\n",
    "        # if token not in cur_word, check next word\n",
    "        if cur+1 < len(word_idxs) and t in word_idxs[cur+1]:\n",
    "            cur += 1\n",
    "            sub_idx = 0\n",
    "        # if not in cur_word or next word, give up and continue\n",
    "        else:\n",
    "            i += 1\n",
    "            result.append((t, \"NA\"))\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
