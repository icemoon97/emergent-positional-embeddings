{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad888284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnb5885/miniconda3/envs/ling/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformer_lens\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fe9b37",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39796f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device_name = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device_name = \"cuda\" # CUDA for NVIDIA GPU\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(f\"Device: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062e5fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2-small\"\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdf677c",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a86780",
   "metadata": {},
   "source": [
    "### Load text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20c3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WORDS = 10000\n",
    "with open('datasets/common_words.txt', 'r') as file:\n",
    "    words = np.random.choice([l.rstrip(\"\\n\") for l in file.readlines()], N_WORDS)\n",
    "    \n",
    "word_len_dict = {w: len(model.to_tokens(f\" {w}\", prepend_bos=False).squeeze(0)) for w in words}\n",
    "word_len = np.vectorize(lambda x: word_len_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4fdbb",
   "metadata": {},
   "source": [
    "### generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a980b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"Hello and welcome to my blog, where I love to list words.\\nWhat \"\n",
    "BATCH_SIZE = 256\n",
    "N_SAMPLE = 10\n",
    "\n",
    "prefix_len = len(model.to_tokens(PREFIX, prepend_bos=True).squeeze(0)) - 1\n",
    "\n",
    "def generate_batch():\n",
    "    batch_words = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        sampled = np.random.choice(words, N_SAMPLE)\n",
    "\n",
    "        batch_words.append(sampled)\n",
    "\n",
    "    tokens = model.to_tokens([PREFIX + \" \".join(s) for s in batch_words], prepend_bos=True)\n",
    "    mapped_len = word_len(batch_words)\n",
    "\n",
    "    word_idxs = np.ones((BATCH_SIZE, N_SAMPLE * 3)) * -1\n",
    "    for i, r in enumerate(mapped_len):\n",
    "        row = np.repeat(np.arange(N_SAMPLE), r)\n",
    "        word_idxs[i, :len(row)] = row\n",
    "\n",
    "    return tokens, word_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a08d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:13<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_BATCHES = 50\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "all_resids = []\n",
    "all_word_idxs = []\n",
    "\n",
    "for i_batch in tqdm(range(DATA_BATCHES)):\n",
    "    tokens, word_idxs = generate_batch()\n",
    "    _, cache = model.run_with_cache(tokens, names_filter=lambda x: x.endswith(\"resid_post\"))\n",
    "    residuals = cache.stack_activation(\"resid_post\")\n",
    "\n",
    "    residuals = residuals[:, :, prefix_len:, :]\n",
    "    word_idxs = word_idxs[:, :residuals.size(dim=2)]\n",
    "\n",
    "    mask = word_idxs != -1\n",
    "\n",
    "    all_resids.append(residuals.cpu().numpy()[:, mask].reshape(12, -1, model.cfg.d_model))\n",
    "    all_word_idxs.append(word_idxs[mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6df234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 158383, 768)\n",
      "(158383,)\n"
     ]
    }
   ],
   "source": [
    "x_all_layers = np.concatenate(all_resids, axis=1)\n",
    "y = np.concatenate(all_word_idxs)\n",
    "\n",
    "print(x_all_layers.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf3ee3",
   "metadata": {},
   "source": [
    "## Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d177765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbingDataset(Dataset):\n",
    "    def __init__(self, act, y):\n",
    "        assert len(act) == len(y)\n",
    "        print(f\"dataset: {len(act)} pairs loaded...\")\n",
    "        self.act = act\n",
    "        self.y = y\n",
    "        print(\"y:\", np.unique(y, return_counts=True))\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.act[idx]), torch.tensor(self.y[idx]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5784815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 158383 pairs loaded...\n",
      "y: (array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), array([15878, 15793, 15871, 15914, 15859, 15881, 15847, 15800, 15780,\n",
      "       15760]))\n",
      "split into [test/train], [31677/126706]\n"
     ]
    }
   ],
   "source": [
    "LAYER = 3\n",
    "x = x_all_layers[LAYER, :, :]\n",
    "\n",
    "probing_dataset = ProbingDataset(x, y)\n",
    "train_size = int(0.8 * len(probing_dataset))\n",
    "test_size = len(probing_dataset) - train_size\n",
    "probe_train_dataset, probe_test_dataset = torch.utils.data.random_split(probing_dataset, [train_size, test_size])\n",
    "print(f\"split into [test/train], [{test_size}/{train_size}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6db8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, num_input_features, num_classes):\n",
    "        super(LinearProbe, self).__init__()\n",
    "        self.linear = nn.Linear(num_input_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ea0f68e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.621112, Acc: 0.748749: 100%|██████████| 50/50 [01:37<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "probe = LinearProbe(768, 10).to(device)\n",
    "\n",
    "config = {\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-3,\n",
    "    'batch_size': 1024,\n",
    "    'num_epochs': 50,\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(probe.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "\n",
    "dataloader = DataLoader(probe_train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "# simple training loop\n",
    "bar = tqdm(range(config['num_epochs']))\n",
    "for epoch in bar:\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = probe(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # train accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    bar.set_description(f'Epoch {epoch+1}, Loss: {running_loss/len(dataloader):.6f}, Acc: {correct/total:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45a8046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 73.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.73621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(probe_test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "probe.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = probe(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        y_pred.append(predicted.cpu().numpy())\n",
    "\n",
    "print(f'Test Accuracy: {correct/total:.5f}')\n",
    "\n",
    "y_pred = np.concatenate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1cf7be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.982     0.995     0.988      3226\n",
      "         1.0      0.974     0.949     0.961      3103\n",
      "         2.0      0.886     0.917     0.902      3277\n",
      "         3.0      0.798     0.791     0.795      3120\n",
      "         4.0      0.721     0.677     0.698      3172\n",
      "         5.0      0.608     0.653     0.630      3156\n",
      "         6.0      0.587     0.539     0.562      3181\n",
      "         7.0      0.534     0.589     0.560      3121\n",
      "         8.0      0.535     0.469     0.500      3127\n",
      "         9.0      0.718     0.772     0.744      3194\n",
      "\n",
      "    accuracy                          0.736     31677\n",
      "   macro avg      0.734     0.735     0.734     31677\n",
      "weighted avg      0.735     0.736     0.735     31677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y[probe_test_dataset.indices], y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
